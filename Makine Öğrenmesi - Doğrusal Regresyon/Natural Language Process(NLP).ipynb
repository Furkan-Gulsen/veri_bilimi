{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Process(NLP)\n",
    "- Makine ile insan arasında ki iletişimi sağlamak için oluşturulmuş bir machine learning yöntemidir.\n",
    "- Cleanin Data\n",
    "- Bag Of Words\n",
    "- Text Classification\n",
    "<br><br>\n",
    "- Nerelerde Kullanılır:\n",
    "- - Predict genre of book\n",
    "- - Question - Answer\n",
    "- - Summarization Of Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20045</td>\n",
       "      <td>815757572</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8/5/15 21:16</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/656793310...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>@lookupondeath ...Fine, and I'll drink tea too...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>783</td>\n",
       "      <td>10/26/15 13:20</td>\n",
       "      <td>6.587400e+17</td>\n",
       "      <td>Verona ªÁ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20046</td>\n",
       "      <td>815757681</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8/15/12 21:17</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/639815429...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greg Hardy you a good player and all but don't...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13523</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20047</td>\n",
       "      <td>815757830</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9/3/12 1:17</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/655473271...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>You can miss people and still never want to se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26419</td>\n",
       "      <td>10/26/15 13:20</td>\n",
       "      <td>6.587400e+17</td>\n",
       "      <td>Lagos Nigeria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20048</td>\n",
       "      <td>815757921</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/6/12 23:46</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657716093...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@bitemyapp i had noticed your tendency to pee ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56073</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Texas Hill Country</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20049</td>\n",
       "      <td>815757985</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/14/14 17:22</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/655134724...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>I think for my APUSH creative project I'm goin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2922</td>\n",
       "      <td>10/26/15 13:19</td>\n",
       "      <td>6.587400e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20050 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0      815719226    False   finalized                   3    10/26/15 23:24   \n",
       "1      815719227    False   finalized                   3    10/26/15 23:30   \n",
       "2      815719228    False   finalized                   3    10/26/15 23:33   \n",
       "3      815719229    False   finalized                   3    10/26/15 23:10   \n",
       "4      815719230    False   finalized                   3     10/27/15 1:15   \n",
       "...          ...      ...         ...                 ...               ...   \n",
       "20045  815757572     True      golden                 259               NaN   \n",
       "20046  815757681     True      golden                 248               NaN   \n",
       "20047  815757830     True      golden                 264               NaN   \n",
       "20048  815757921     True      golden                 250               NaN   \n",
       "20049  815757985     True      golden                 249               NaN   \n",
       "\n",
       "       gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0        male             1.0000        yes                    1.0   \n",
       "1        male             1.0000        yes                    1.0   \n",
       "2        male             0.6625        yes                    1.0   \n",
       "3        male             1.0000        yes                    1.0   \n",
       "4      female             1.0000        yes                    1.0   \n",
       "...       ...                ...        ...                    ...   \n",
       "20045  female             1.0000        yes                    1.0   \n",
       "20046    male             1.0000        yes                    1.0   \n",
       "20047    male             1.0000        yes                    1.0   \n",
       "20048  female             0.8489        yes                    1.0   \n",
       "20049  female             1.0000        yes                    1.0   \n",
       "\n",
       "              created  ...                                       profileimage  \\\n",
       "0        12/5/13 1:48  ...  https://pbs.twimg.com/profile_images/414342229...   \n",
       "1       10/1/12 13:51  ...  https://pbs.twimg.com/profile_images/539604221...   \n",
       "2      11/28/14 11:30  ...  https://pbs.twimg.com/profile_images/657330418...   \n",
       "3       6/11/09 22:39  ...  https://pbs.twimg.com/profile_images/259703936...   \n",
       "4       4/16/14 13:23  ...  https://pbs.twimg.com/profile_images/564094871...   \n",
       "...               ...  ...                                                ...   \n",
       "20045    8/5/15 21:16  ...  https://pbs.twimg.com/profile_images/656793310...   \n",
       "20046   8/15/12 21:17  ...  https://pbs.twimg.com/profile_images/639815429...   \n",
       "20047     9/3/12 1:17  ...  https://pbs.twimg.com/profile_images/655473271...   \n",
       "20048   11/6/12 23:46  ...  https://pbs.twimg.com/profile_images/657716093...   \n",
       "20049   4/14/14 17:22  ...  https://pbs.twimg.com/profile_images/655134724...   \n",
       "\n",
       "       retweet_count sidebar_color  \\\n",
       "0                  0        FFFFFF   \n",
       "1                  0        C0DEED   \n",
       "2                  1        C0DEED   \n",
       "3                  0        C0DEED   \n",
       "4                  0             0   \n",
       "...              ...           ...   \n",
       "20045              0        C0DEED   \n",
       "20046              0             0   \n",
       "20047              0        C0DEED   \n",
       "20048              0             0   \n",
       "20049              0        C0DEED   \n",
       "\n",
       "                                                    text tweet_coord  \\\n",
       "0      Robbie E Responds To Critics After Win Against...         NaN   \n",
       "1      ÛÏIt felt like they were my friends and I was...         NaN   \n",
       "2      i absolutely adore when louis starts the songs...         NaN   \n",
       "3      Hi @JordanSpieth - Looking at the url - do you...         NaN   \n",
       "4      Watching Neighbours on Sky+ catching up with t...         NaN   \n",
       "...                                                  ...         ...   \n",
       "20045  @lookupondeath ...Fine, and I'll drink tea too...         NaN   \n",
       "20046  Greg Hardy you a good player and all but don't...         NaN   \n",
       "20047  You can miss people and still never want to se...         NaN   \n",
       "20048  @bitemyapp i had noticed your tendency to pee ...         NaN   \n",
       "20049  I think for my APUSH creative project I'm goin...         NaN   \n",
       "\n",
       "      tweet_count   tweet_created      tweet_id      tweet_location  \\\n",
       "0          110964  10/26/15 12:40  6.587300e+17     main; @Kan1shk3   \n",
       "1            7471  10/26/15 12:40  6.587300e+17                 NaN   \n",
       "2            5617  10/26/15 12:40  6.587300e+17              clcncl   \n",
       "3            1693  10/26/15 12:40  6.587300e+17       Palo Alto, CA   \n",
       "4           31462  10/26/15 12:40  6.587300e+17                 NaN   \n",
       "...           ...             ...           ...                 ...   \n",
       "20045         783  10/26/15 13:20  6.587400e+17          Verona ªÁ   \n",
       "20046       13523  10/26/15 12:40  6.587300e+17     Kansas City, MO   \n",
       "20047       26419  10/26/15 13:20  6.587400e+17      Lagos Nigeria    \n",
       "20048       56073  10/26/15 12:40  6.587300e+17  Texas Hill Country   \n",
       "20049        2922  10/26/15 13:19  6.587400e+17                 NaN   \n",
       "\n",
       "                    user_timezone  \n",
       "0                         Chennai  \n",
       "1      Eastern Time (US & Canada)  \n",
       "2                        Belgrade  \n",
       "3      Pacific Time (US & Canada)  \n",
       "4                             NaN  \n",
       "...                           ...  \n",
       "20045                         NaN  \n",
       "20046                         NaN  \n",
       "20047                         NaN  \n",
       "20048                         NaN  \n",
       "20049                         NaN  \n",
       "\n",
       "[20050 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(r\"gender_classifier.csv\",encoding=\"latin1\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20045</td>\n",
       "      <td>female</td>\n",
       "      <td>(rp)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20046</td>\n",
       "      <td>male</td>\n",
       "      <td>Whatever you like, it's not a problem at all. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20047</td>\n",
       "      <td>male</td>\n",
       "      <td>#TeamBarcelona ..You look lost so you should f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20048</td>\n",
       "      <td>female</td>\n",
       "      <td>Anti-statist; I homeschool my kids. Aspiring t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20049</td>\n",
       "      <td>female</td>\n",
       "      <td>Teamwork makes the dream work.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender                                        description\n",
       "0        male                              i sing my own rhythm.\n",
       "1        male  I'm the author of novels filled with family dr...\n",
       "2        male                louis whining and squealing and all\n",
       "3        male  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
       "4      female  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...\n",
       "...       ...                                                ...\n",
       "20045  female                                               (rp)\n",
       "20046    male  Whatever you like, it's not a problem at all. ...\n",
       "20047    male  #TeamBarcelona ..You look lost so you should f...\n",
       "20048  female  Anti-statist; I homeschool my kids. Aspiring t...\n",
       "20049  female                     Teamwork makes the dream work.\n",
       "\n",
       "[16224 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data.gender,data.description],axis=1) # axis=1 for columns\n",
    "data.dropna(axis=0,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20045</td>\n",
       "      <td>0</td>\n",
       "      <td>(rp)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20046</td>\n",
       "      <td>1</td>\n",
       "      <td>Whatever you like, it's not a problem at all. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20047</td>\n",
       "      <td>1</td>\n",
       "      <td>#TeamBarcelona ..You look lost so you should f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20048</td>\n",
       "      <td>0</td>\n",
       "      <td>Anti-statist; I homeschool my kids. Aspiring t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20049</td>\n",
       "      <td>0</td>\n",
       "      <td>Teamwork makes the dream work.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender                                        description\n",
       "0           1                              i sing my own rhythm.\n",
       "1           1  I'm the author of novels filled with family dr...\n",
       "2           1                louis whining and squealing and all\n",
       "3           1  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
       "4           0  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...\n",
       "...       ...                                                ...\n",
       "20045       0                                               (rp)\n",
       "20046       1  Whatever you like, it's not a problem at all. ...\n",
       "20047       1  #TeamBarcelona ..You look lost so you should f...\n",
       "20048       0  Anti-statist; I homeschool my kids. Aspiring t...\n",
       "20049       0                     Teamwork makes the dream work.\n",
       "\n",
       "[16224 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# male = 0\n",
    "# female = 1\n",
    "data.gender = [1 if each == \"male\" else 0 for each in data.gender]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ricky Wilson The Best FRONTMAN/Kaiser Chiefs The Best BAND Xxxx Thank you Kaiser Chiefs for an incredible year of gigs and memories to cherish always :) Xxxxxxx'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning\n",
    "## regular expression\n",
    "import re\n",
    "\n",
    "# for example\n",
    "first_description = data.description[4]\n",
    "first_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ricky Wilson The Best FRONTMAN Kaiser Chiefs The Best BAND Xxxx Thank you Kaiser Chiefs for an incredible year of gigs and memories to cherish always    Xxxxxxx'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = re.sub(\"[^a-zA-Z]\",\" \",first_description)\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ricky wilson the best frontman kaiser chiefs the best band xxxx thank you kaiser chiefs for an incredible year of gigs and memories to cherish always    xxxxxxx'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = description.lower() # küçük harfe çevirme\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword : gereksiz kelimeler\n",
    "from nltk.corpus import stopwords\n",
    "import nltk # natural language tool kit\n",
    "# nltk.download(\"stopwords\") # corpus adlı bir klasöre indiriliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description = description.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ricky',\n",
       " 'wilson',\n",
       " 'the',\n",
       " 'best',\n",
       " 'frontman',\n",
       " 'kaiser',\n",
       " 'chiefs',\n",
       " 'the',\n",
       " 'best',\n",
       " 'band',\n",
       " 'xxxx',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'kaiser',\n",
       " 'chiefs',\n",
       " 'for',\n",
       " 'an',\n",
       " 'incredible',\n",
       " 'year',\n",
       " 'of',\n",
       " 'gigs',\n",
       " 'and',\n",
       " 'memories',\n",
       " 'to',\n",
       " 'cherish',\n",
       " 'always',\n",
       " 'xxxxxxx']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split yerine tokenizer kullanabiliriz\n",
    "description = nltk.word_tokenize(description)\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gereksiz kelimeleri at (at,the gibi)\n",
    "description = [word for word in description if not word in set(stopwords.words(\"english\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatazation : kökleri bulma\n",
    "import nltk as nlp\n",
    "lemma = nlp.WordNetLemmatizer()\n",
    "description = [ lemma.lemmatize(word) for word in description]\n",
    "\n",
    "description = \" \".join(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i   s i n g   m y   o w n   r h y t h m  '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "import nltk as nlp\n",
    "\n",
    "data = pd.read_csv(r\"gender_classifier.csv\",encoding=\"latin1\")\n",
    "data = pd.concat([data.gender,data.description],axis=1) # axis=1 for columns\n",
    "data.dropna(axis=0,inplace=True)\n",
    "data.gender = [1 if each == \"male\" else 0 for each in data.gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bütün datalar için;\n",
    "description_list = []\n",
    "for description in data.description:\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \", description)\n",
    "    description = description.lower()\n",
    "    description = nltk.word_tokenize(description)\n",
    "    #description = [word for word in description if not word in set(stopwords.words(\"english\"))]\n",
    "    # yukarıda ki yapıyı aşağıda daha hızlı çalıştırılan bir metoda yazdık\n",
    "    lemma = nlp.WordNetLemmatizer()\n",
    "    description = [ lemma.lemmatize(word) for word in description ]\n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "# 1-ben okula döndüm\n",
    "# 2-ben yarın okula dönüceğim\n",
    "# 3-yarın okulda ne işin var\n",
    "# cümleler    ben okul dönmek yarın ne iş var\n",
    "#    1         1   1     1      0   0  0   0\n",
    "#    2         1   1     1      1   0  0   0\n",
    "#    3         0   1     0      1   1  1   1\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # bag of words için kullanılan metod\n",
    "max_features = 5000 # 32000 kelimenin içerisinden en çok kullanılan 5000 kelime\n",
    "count_vectorizer = CountVectorizer(max_features=max_features,stop_words=\"english\")\n",
    "# CountVectorizer(max_feature=max_feature,stop_words=\"english\",lowercase=true,token_pattern=\"[^a-zA-Z]\")\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray() # 0 ve 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"en sık kullanılan {} kelimeler: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text classification\n",
    "y = data.iloc[:,0].values # kadın erkek\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sparce_matrix # kelimeler için 0-1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (14601, 5000)\n",
      "x_test (1623, 5000)\n",
      "y_train (14601,)\n",
      "y_test (1623,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1,random_state=42)\n",
    "\n",
    "print(\"x_train\",x_train.shape)\n",
    "print(\"x_test\",x_test.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  45.40973505853358\n"
     ]
    }
   ],
   "source": [
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = nb.predict(x_test)\n",
    "print(\"Accuracy: \", nb.score(x_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
